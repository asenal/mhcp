#!/usr/bin/python
import os,sys,re,string,math,random,sqlite3
from getopt import getopt
here=os.path.realpath('./')
sys.path.append(here+'/libs')
import hla
sys.path.append(here+'/libs/libsvm-3.12/python')
#sys.path.append(here+'/libs/libsvm-3.16/python')
import svmutil

# step0 : parameter processing
opts,args=getopt(sys.argv[1:],'hw:t:p:m',["help","window=","type=","pssm=","model="])
# store all the options in a dict 'opts';store anonymous args into 'args'
for key,value in opts:
    if key in ("-h","--help"):
        msg="""This is a script to train & predict MHCP peptide.
Input a fasta file,the script will cut them into kmers and output the most probably one. This is a copy left software,use & modify it however you like.

Contact:
liugeng@genomics.cn;yuqiulin@genomics.cn

Usage:
python %s --window=9 --types="['HLA-DR6','HLA-DR1']" --fasta peptide.fasta

Parameters:
-h/--help : print this help msg.
-w/--window: window size of the minimium kmer
-t/--types: HLA types.If you intend to predict all the peptides in more than one scope,give a list quoted in [ ]
-p/--pssm: a pssm matrix [not support yet]
-m/--model: a precomputed svm model for a specified HLA type,a default model is used if omitted
-f/--fasta: peptides to be detect is stored in a fasta file
-o/--output: output file,in the format of 'fasta_ID:start:end:hla-type:prob' """ % sys.argv[0]
        print msg
        sys.exit(1)
    if key in ("-m","--model"):
        model_file=value
        print 'model file chosen: %s' % model_file
    if key in ("-w","--window"):
        window=value
    if key in ("-f","--fasta"):
        fasta=value
    if key in ("-o","--output"):
        output=value
    if key in ("-t","--type"):
        hla_types=eval(value)
        print 'hla-type to be detect: %s' % hla_types

# some defaults:
window=9
fasta='./data/test.fasta'
hla_types=['HLA-DR6','HLA-DR1']
limit=100 # take at most 200 hlas
random_chunk=2000
output='./output/out.txt'

##step1 : convert mhcpep.txt into sqltie3
conn=sqlite3.connect(here+'/data/mhcp.db')
curs=conn.cursor()
mhcpep_file=here+'/data/mhcpep.txt'
if hla.check_table(curs,'mhcpep'):
    pass
else:
    hla.storeDB_mhcpep(curs,records)
conn.commit()
conn.close()

#step2.1 : get random negtive samples,random.aa is a fasta file with one-line title and seq.
random_kmers=hla.get_random_kmers(random_chunk,window)

#step2.2 : get mhcp positive kmers
records=hla.read_mhcpep(mhcpep_file)
hla_seqs=[]
for hla_type in hla_types:
    hla_seqs.extend([i['sequence'].strip('*') for i in records if i['hla'] == hla_type and i['type'] == 'CLASS-2'])
if len(hla_seqs) > limit: hla_seqs=hla_seqs[0:limit-1]
hla_kmers=[]
for seq in hla_seqs:
     hla_kmers.extend(hla.score_slide(seq,9))
     
#step3.1 : convert hla/random kmers into trainset / testset
train_data,train_labels,test_data,test_labels=hla.trainset_convert(random_kmers,hla_kmers,0.7,hla.int_table)

# step3.2 : train svm
problem=svmutil.svm_problem(train_labels,train_data)
pram=svmutil.svm_parameter('-s 0 -t 2 -b 1')
model=svmutil.svm_train(problem,pram)
svmutil.svm_save_model('%s/output/test.model' % here,model)

# step3.3 : test with known data
# tobe continued... asenal  no, save it. training will do the test internally
# maybe in the same framework with 'predict module' but input real 'y' lables
# step3.3 : test & cross-validation
#p_label,p_acc,p_val=svmutil.svm_predict(test_labels,test_data,model, '-b 1')
#p_label,p_acc,p_val=svmutil.svm_predict(test_labels,test_data,model)
#ACC, MSE, SCC = svmutil.evaluations(test_labels, p_label)

# step4 : predict 
for item in hla.read_fasta(fasta):
    title,seq=item[0],item[1]
    kmers=hla.slide(seq,window)
    kmers=map(lambda x:hla.aa_translate(x,hla.int_table),kmers)
    y=len(kmers)*[1]
    p_label=svmutil.svm_predict(y,kmers,model,'-b 1')
    print p_label
# step5: eval: ROC,cross validation [not support yet]
# tobe continued ... asenal
    
"""
NOTES:
svm_type=mdoel.get_svm_type()
nr_class=model.get_nr_class()
svr_probability=model.get_svr_probability()
class_labels=model.get_labels()
is_prob_model=model.is_probability_model()
suport_vectors=mdoel.get_SV()
support_vector_coefficients=model.get_sv_coef()

model=svm_train(y,x,'-t 2 -c 5') / (problem) / (problem,param) all  is good.
Y type must be int/double. param is generated by svm_parameter('training options'), problem is generated by svm_problem(y,x[isKernel=True]).

p_labels, p_acc, p_vals=svm_predict(y,x,model,'predict options')
p_vals is a list of decision values or probability estimates (if '-b 1' is specified) . If k is the number of classes in training data,for decision values,each element  includes results of predictiong K(K-1)/2 binary-class SVMs. For classification,k=1 is a special case. Decision value [+1] is returned for each testing instance,instead of an empty list. For probabilityes ,each element contains K values indicating the probability that the testing instance is in each class.The order of classes is the same as the  'model.label' field in the mdoel structure.

svm_read_problem(y,x)
y,x = svm_load_model('../mhcp.txt')
svm_save_model()
ACC,MSE,SCC = evaluations(ty,pv): ty is a list of true values;pv is a list of predict values;SCC is squared correlation coefficien,MSE=mean squared error,ACC=accuracy
"""
